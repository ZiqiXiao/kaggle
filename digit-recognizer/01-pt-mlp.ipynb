{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the directory structure and download the data from Kaggle\n",
    "# !mkdir -p ~/DataspellProjects/kaggle/digit-recognizer/data\n",
    "# !cd ~/DataspellProjects/kaggle/digit-recognizer/data\n",
    "# !kaggle competitions download -c digit-recognizer\n",
    "# !unzip digit-recognizer.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import Generator\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples is: 42000\n"
     ]
    }
   ],
   "source": [
    "print('number of training samples is:', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = i * 28 + j, where i is the row and j is the column\n",
    "# transfer the data to a 28x28 tensor matrix\n",
    "train_x = train.iloc[:, 1:].values.astype(float).reshape(-1, 1, 28, 28)\n",
    "train_y = train.iloc[:, 0].values\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create image dataset for preprocessing and augmentation\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, ids, X_transform=None, y_transform=None):\n",
    "        self.ids=ids\n",
    "        self.X_transform=X_transform\n",
    "        self.y_transform=y_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.ids.iloc[index, 1:].values.astype('float32').reshape(1, 28, 28)\n",
    "        if self.X_transform:\n",
    "            image = self.X_transform(image)\n",
    "\n",
    "        label = self.ids.iloc[index, 0]\n",
    "        if self.y_transform:\n",
    "            label = self.y_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imageDataLoader(\n",
    "        raw_data,\n",
    "        batch_size=64,\n",
    "        train_test_split=0.3,\n",
    "        seed=0,\n",
    "        X_transform=None,\n",
    "        y_transform=None\n",
    "):\n",
    "\n",
    "    dataset = ImageDataset(raw_data, X_transform=X_transform, y_transform=y_transform)\n",
    "    train_set, val_set = random_split(\n",
    "        dataset,\n",
    "        [(1-train_test_split), train_test_split],\n",
    "        generator=Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    #DataLoaders\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader= DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.RandomRotation((-10.0, 10.0)),\n",
    "    transforms.RandomSolarize(p=0.5, threshold=0.5),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1,0.1)),\n",
    "])\n",
    "\n",
    "y_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = imageDataLoader(\n",
    "    train,\n",
    "    batch_size=64,\n",
    "    train_test_split=0.3,\n",
    "    seed=0,\n",
    "    X_transform=X_transform,\n",
    "    # y_transform=y_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([64])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.dtype)\n",
    "    print(y.shape)\n",
    "    print(y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the model: MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/DataspellProjects/kaggle/digit-recognizer/models\n",
    "!mkdir -p ~/DataspellProjects/kaggle/digit-recognizer/tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('tb_logs/MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    best_val_acc = 0\n",
    "\n",
    "    model.to(device) # set the model to the device\n",
    "    model.train() # set the model to training mode\n",
    "    # training loop\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        train_acc += (output.argmax(1) == y).cpu().type(torch.float).sum()\n",
    "\n",
    "    writer.add_scalar('training loss',\n",
    "                      train_loss / len(train_loader.dataset),\n",
    "                      epoch+1)\n",
    "\n",
    "    writer.add_scalar('training accuracy',\n",
    "                      train_acc / len(train_loader.dataset),\n",
    "                      epoch+1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # set the model to evaluation mode\n",
    "        # validation loop\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            val_loss += loss.item() * X.size(0)\n",
    "            val_acc += (output.argmax(1) == y).cpu().type(torch.float).sum()\n",
    "\n",
    "    writer.add_scalar('validation loss',\n",
    "                      val_loss / len(val_loader.dataset),\n",
    "                      epoch+1)\n",
    "\n",
    "    writer.add_scalar('validation accuracy',\n",
    "                      val_acc / len(val_loader.dataset),\n",
    "                      epoch+1)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'models/model.pt')\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = train_acc / len(train_loader.dataset)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_acc / len(val_loader.dataset)\n",
    "    print(f'Epoch: {epoch + 1}: Training Loss: {train_loss:.4f} \\tValidation Loss: {val_loss:.4f} \\tTraining Accuracy: {train_acc:.4f} \\tValidation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b6bcfff880054a51\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b6bcfff880054a51\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.values.reshape(-1, 28, 28)\n",
    "test = torch.from_numpy(test)\n",
    "test = test.unsqueeze(1)\n",
    "test = test.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.load_state_dict(torch.load('models/model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.to(device)\n",
    "output = model(test)\n",
    "output = output.argmax(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/DataspellProjects/kaggle/digit-recognizer/submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': range(1, len(output)+1), 'Label': output})\n",
    "submission.to_csv('submissions/mlp_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/xiaoziqi/.kaggle/kaggle.json'\n",
      "100%|████████████████████████████████████████| 208k/208k [00:03<00:00, 55.6kB/s]\n",
      "Successfully submitted to Digit Recognizer"
     ]
    }
   ],
   "source": [
    "# make submission\n",
    "!kaggle competitions submit -c digit-recognizer -f ~/DataspellProjects/kaggle/digit-recognizer/submissions/mlp_submission.csv -m \"MLP submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
